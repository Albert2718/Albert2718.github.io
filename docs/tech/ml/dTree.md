决策树（Decision Tree）是一种常用的机器学习算法，广泛应用于分类和回归问题。

决策树通过树状结构来表示决策过程，每个内部节点代表一个特征或属性的测试，每个分支代表测试的结果，每个叶节点代表一个类别或值。

![alt text](images/image.png)

## 构建标准

### CART - Gini Index

Gini指数用于衡量数据集的纯度。计算公式如下：
$$Gini(D) = 1 - \sum_{i=1}^{C} p_i^2$$
其中，\(p_i\)表示类别\(i\)在数据集D中的比例，C表示类别的总数。

个人觉得还是蛮直观的，既然代表的是纯度，那作为决策树中的构建标准，我们肯定希望构建后的Gini指数更小，这样代表数据集更纯净，正反例分得更清楚，所以在选择划分属性时，我们会选择使得Gini指数最小的属性进行划分。

更加直观一点的解释可以看这篇文章：<https://www.cnblogs.com/wang_yb/p/18196100>

## 剪枝